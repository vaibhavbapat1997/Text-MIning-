{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGjxkyQNyH7N"
   },
   "source": [
    "# Topic Modeling for hotel207reviews data\n",
    "Filename: topic_modeling_hotel207reviews.ipynb\n",
    "- Load data (207 records are stored in 223 rows as some reviews were entered in multiple rows)   \n",
    "  Data source: https://<span></span>monkeylearn.com/blog/introduction-to-topic-modeling/\n",
    "- Compute term-document matrix with lemmatization\n",
    "- Latent semantic analysis (LSA)\n",
    "- Non-negative matrix factorization (MNF)\n",
    "- Latent Dirichlet allocation (LDA)\n",
    "- Grid search for the best number of topics (and other parameters) for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1647619764534,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "vQFipGG8vZ5p",
    "outputId": "2123f8f8-9455-4b02-9f5c-73407a235a5c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "#import graphviz as gr\n",
    "%matplotlib inline\n",
    "style.use(\"fivethirtyeight\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647619764535,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "OFysFV6NyH7R",
    "outputId": "b050e5a4-9dbd-4c11-a38e-0d85a7614e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207 entries, 0 to 206\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       207 non-null    object\n",
      " 1   Sentiment  207 non-null    object\n",
      " 2   Topic      207 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.0+ KB\n",
      "\n",
      "Sentiment values:  ['negative' 'positive']\n",
      "Topic values:  ['Comfort' 'Facilities' 'Cleanliness']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The rooms are extremely small, practically onl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Room safe did not work.</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mattress very comfortable.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very uncomfortable, thin mattress, with plasti...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No bathroom in room</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The bed was soooo comfy.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>someone must have been smoking in the room nex...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Cleanliness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The bed is very comfortable.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Very spacious rooms, quiet and very comfortable.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For 3 people in a bedroom the sofa bed is a bi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lights in the common room were too dim.</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Air conditioning working fine.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So if you're the type that likes to let water ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the windows are only single glazed so the heat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Terrible, small cubbyholes, which are marketed...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Corridors filthy\\r\\nRoom filthy\\r\\nElectrical ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Cleanliness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>walls seem to have no sound insulation</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The gym was very small and basic</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text Sentiment        Topic\n",
       "0   The rooms are extremely small, practically onl...  negative      Comfort\n",
       "1                             Room safe did not work.  negative   Facilities\n",
       "2                          Mattress very comfortable.  positive      Comfort\n",
       "3   Very uncomfortable, thin mattress, with plasti...  negative      Comfort\n",
       "4                                 No bathroom in room  negative   Facilities\n",
       "5                            The bed was soooo comfy.  positive      Comfort\n",
       "6   someone must have been smoking in the room nex...  negative  Cleanliness\n",
       "7                        The bed is very comfortable.  positive      Comfort\n",
       "8    Very spacious rooms, quiet and very comfortable.  positive      Comfort\n",
       "9   For 3 people in a bedroom the sofa bed is a bi...  negative      Comfort\n",
       "10            Lights in the common room were too dim.  negative   Facilities\n",
       "11                     Air conditioning working fine.  positive      Comfort\n",
       "12  So if you're the type that likes to let water ...  negative   Facilities\n",
       "13  the windows are only single glazed so the heat...  negative      Comfort\n",
       "14  Terrible, small cubbyholes, which are marketed...  negative   Facilities\n",
       "15  Corridors filthy\\r\\nRoom filthy\\r\\nElectrical ...  negative  Cleanliness\n",
       "16             walls seem to have no sound insulation  negative   Facilities\n",
       "17                   The gym was very small and basic  negative   Facilities"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data (207 reviews are stored in 223 rows as some reviews were entered in multiple rows)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "textdf = pd.read_csv('hotel207reviews.csv')\n",
    "textdf.info()\n",
    "print('\\nSentiment values: ', textdf.Sentiment.unique())\n",
    "print('Topic values: ', textdf.Topic.unique())\n",
    "textdf.head(18)  # row 15 \"Corridors filthy\\r\\nRoom....\" includes 4 rows of data in the CSV file\n",
    "\n",
    "# import csv\n",
    "# reviews = [row for row in csv.reader(open('C:/Courses/MIST.7060(63.706)/Datasets/hotel223reviews.csv'))]\n",
    "# reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647619764536,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "rs1sgeCQydr0",
    "outputId": "5f854893-9ef4-4307-ceba-1bf75aeaefc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fromx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fromx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fromx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1647619764725,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "b-ICXAd1yH7T",
    "outputId": "704aec93-dd02-4f83-b59c-fec2c049085f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '12am', '15', '15th', '1990s', '2', '240', '3', '30', '302', '4', '40', '4th', '5', '58', '6', '650', '7', 'abundant', 'ac', 'access', 'actually', 'added', 'adjust', 'adult', 'advertised', 'advised', 'agreed', 'ahead', 'air', 'aircon', 'allow', 'amazing', 'ambience', 'amenity', 'amenityi', 'ample', 'anda', 'andor', 'anymore', 'apart', 'appeal', 'area', 'arent', 'art', 'available', 'avenue', 'awesome', 'bag', 'bar', 'barely', 'basic', 'bath', 'bathroom', 'bathtub', 'bed', 'bedding', 'bedroom', 'best', 'big', 'bigger', 'bit', 'blanket', 'blind', 'boil', 'book', 'bookingcom', 'bothering', 'bright', 'broken', 'building', 'bunting', 'cable', 'called', 'came', 'cap', 'card', 'carpet', 'center', 'challenge', 'change', 'changed', 'channel', 'character', 'charge', 'city', 'classy', 'clean', 'cleaned', 'cleaning', 'closed', 'closest', 'closet', 'cm', 'cockroach', 'coffee', 'cold', 'come', 'comfortable', 'comfy', 'coming', 'common', 'compared', 'condition', 'conditioning', 'connected', 'construction', 'control', 'convenient', 'cool', 'corridor', 'cosy', 'cot', 'couch', 'count', 'counter', 'cover', 'covered', 'covering', 'cramped', 'crumb', 'cubbyhole', 'curb', 'curtain', 'customer', 'day', 'decent', 'deco', 'decor', 'degree', 'description', 'design', 'detest', 'device', 'did', 'didnt', 'different', 'dim', 'dimly', 'dirty', 'dollar', 'dont', 'door', 'double', 'downstairs', 'draft', 'drape', 'dust', 'earplug', 'easy', 'electrical', 'elegant', 'elevator', 'engineer', 'english', 'enjoyed', 'entrance', 'escape', 'especially', 'essential', 'everyday', 'excellent', 'execellent', 'exercise', 'expected', 'extended', 'extra', 'extremely', 'facility', 'fair', 'family', 'fan', 'far', 'fast', 'febreeze', 'feel', 'felt', 'figure', 'filled', 'filthy', 'fine', 'fit', 'fitness', 'fixed', 'flat', 'floor', 'fluctuated', 'foam', 'free', 'freezing', 'fresh', 'friend', 'frosted', 'functioned', 'futon', 'garbage', 'getting', 'glass', 'glazed', 'gon', 'good', 'got', 'great', 'greatest', 'guest', 'gym', 'ha', 'hadnt', 'hair', 'hairdryer', 'halfhearted', 'hallway', 'hand', 'handle', 'hanging', 'hard', 'havent', 'heat', 'heating', 'heavy', 'highly', 'hip', 'hold', 'hole', 'hot', 'hotel', 'hotter', 'hour', 'hr', 'huge', 'hvac', 'ice', 'id', 'idea', 'immaculate', 'improvement', 'insufficient', 'insulation', 'intense', 'interior', 'inviting', 'iron', 'isntant', 'issue', 'jet', 'jiggled', 'just', 'kettle', 'king', 'kitchen', 'knew', 'lantern', 'large', 'late', 'leaked', 'leave', 'left', 'length', 'let', 'lift', 'light', 'lighting', 'like', 'liked', 'line', 'linen', 'lit', 'little', 'lobby', 'location', 'lock', 'long', 'looked', 'loud', 'loved', 'lovely', 'luggage', 'main', 'make', 'maker', 'making', 'manhattan', 'marketed', 'mattress', 'mean', 'memory', 'microwave', 'mind', 'minimalist', 'minute', 'morning', 'mouse', 'n', 'na', 'narrowit', 'nasty', 'need', 'needed', 'negative', 'nice', 'night', 'noise', 'noisy', 'nyc', 'oher', 'ok', 'old', 'oneon', 'open', 'ordered', 'outlet', 'outside', 'package', 'pain', 'painted', 'panel', 'paper', 'pay', 'peeking', 'people', 'persian', 'phone', 'picture', 'pillow', 'place', 'plastic', 'pleasant', 'plenty', 'plug', 'pool', 'poor', 'potent', 'practically', 'prepaid', 'pressure', 'pretty', 'previous', 'price', 'prior', 'private', 'proof', 'properly', 'protector', 'pry', 'qualiity', 'quality', 'queen', 'quiet', 'quite', 'ran', 'reach', 'real', 'really', 'received', 'renovation', 'replaced', 'repulsive', 'requested', 'rest', 'restaurant', 'restroom', 'retroshower', 'rinsed', 'road', 'roof', 'roofed', 'rooftop', 'room', 'rough', 'rug', 'run', 'rustle', 'safe', 'sanitary', 'scent', 'screen', 'seating', 'selection', 'sep', 'service', 'shared', 'sheet', 'shining', 'shipment', 'shoe', 'shop', 'shower', 'showerroom', 'showertub', 'shutter', 'single', 'sink', 'sit', 'size', 'sized', 'slamming', 'sleep', 'sleeper', 'sleeping', 'slept', 'slow', 'small', 'smaller', 'smell', 'smelled', 'smelly', 'smoking', 'snack', 'sofa', 'soooo', 'soulless', 'sound', 'soundly', 'soundproofing', 'space', 'spacious', 'spaciousthe', 'spartan', 'spotless', 'spread', 'springy', 'stain', 'stale', 'star', 'stay', 'stayed', 'stiff', 'story', 'strong', 'style', 'suitcase', 'suite', 'super', 'support', 'surge', 'tap', 'tea', 'tear', 'television', 'temperature', 'tend', 'terrace', 'terrible', 'terribleespecially', 'thing', 'think', 'tidy', 'tight', 'tile', 'time', 'tiny', 'tissue', 'toilet', 'told', 'towel', 'traffic', 'travel', 'tricky', 'try', 'tub', 'tube', 'turkish', 'turned', 'tv', 'twin', 'type', 'u', 'unbeatable', 'unbelievably', 'unclean', 'uncomfortable', 'unconfortable', 'underneath', 'unit', 'unpack', 'unstitched', 'use', 'used', 'usually', 'value', 'vent', 'view', 'wa', 'wait', 'waited', 'walk', 'walking', 'wall', 'wallpaper', 'wallsnot', 'wanted', 'wardrobe', 'warmer', 'wasnt', 'water', 'way', 'wear', 'werent', 'wet', 'whomever', 'wifi', 'window', 'winter', 'work', 'worked', 'working', 'workout', 'year', 'youre', 'yr']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<207x510 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1077 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute term-document matrix with lemmatization\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def lemma_tokenizer(corpus):   # a method to lemmatize corpus\n",
    "    corpus = ''.join([ch for ch in corpus if ch not in string.punctuation])  # remove punctuation\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "tf_vec = CountVectorizer(tokenizer=lemma_tokenizer, stop_words='english')  # default lowercase\n",
    "tf_sparse = tf_vec.fit_transform(textdf.Text)\n",
    "tf_dictionary = tf_vec.get_feature_names()\n",
    "print(tf_dictionary)\n",
    "tf_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1647619764725,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "6oBkts8qyH7U",
    "outputId": "7af7e302-73b2-40f8-e553-041fa9aea306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<207x510 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1077 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer(tokenizer=lemma_tokenizer, stop_words='english')  # default lowercase\n",
    "tfidf_sparse = tfidf_vec.fit_transform(textdf.Text)\n",
    "tfidf_dictionary = tfidf_vec.get_feature_names()\n",
    "tfidf_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1647619764726,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "6Hqv-1OWyH7U",
    "outputId": "d89f2b07-ce33-49e3-fd65-bfa0285dbb47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Latent semantic analysis (LSA)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa = TruncatedSVD(n_components=3)\n",
    "lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647619764726,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "QNtLVD1AyH7U",
    "outputId": "f8f96008-55d1-4873-bb4b-12df6d6319c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_tf_topics = lsa.fit_transform(tf_sparse)\n",
    "lsa_tf_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647619764726,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "--WYQo4myH7V",
    "outputId": "19b3a9a1-d054-4715-a791-4d1cc30f6f90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 510)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647619764727,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "0E8g3jeZyH7W",
    "outputId": "b2713b67-2eb6-4334-932b-1b8d5826e2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA topics based on term-document matrix:\n",
      "Topic #0: wa room bed small shower comfortable clean cold bathroom hotel\n",
      "Topic #1: room small far didnt bit safe filthy old screen book\n",
      "Topic #2: bed comfortable queen 2 requested comfy terrible far size 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print top terms for each topic\n",
    "def print_top_terms(model, vocabulary, n_top_terms):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([vocabulary[i]\n",
    "                             for i in topic.argsort()[:-n_top_terms - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "print('LSA topics based on term-document matrix:')\n",
    "print_top_terms(lsa, tf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1647619765370,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "k1nlhU3QyH7W",
    "outputId": "842794ed-a064-487d-c319-7fe939a8e813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA topics based on tfidf matrix:\n",
      "Topic #0: wa room clean bed comfortable small spacious cold bathroom comfy\n",
      "Topic #1: bed comfortable comfy terrible mattress super lovely minimalist pillow selection\n",
      "Topic #2: small room extra extremely bathroom open suitcase spacious practically cold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsa.fit_transform(tfidf_sparse)\n",
    "print('LSA topics based on tfidf matrix:')\n",
    "print_top_terms(lsa, tfidf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647619765371,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "shnIExMyyH7X",
    "outputId": "5ceacb39-fd96-44d2-d06a-b25ffc864c03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.5, n_components=3, random_state=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-negative matrix factorization (MNF)\n",
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=3, random_state=1, alpha=.1, l1_ratio=.5)  # alpha and l1 related to regularization\n",
    "nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647619765372,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "J_2aFXe1yH7Y",
    "outputId": "ee001274-0f6d-4905-b039-64ee06bd0526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF topics based on term-document matrix:\n",
      "Topic #0: wa shower cold way bathroom clean water poor pressure night\n",
      "Topic #1: room small didnt spacious far bit old screen filthy safe\n",
      "Topic #2: bed comfortable queen 2 wa requested comfy terrible size sleeping\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf.fit_transform(tf_sparse)\n",
    "print('NMF topics based on term-document matrix:')\n",
    "print_top_terms(nmf, tf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647619765372,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "WAlaoUrAyH7Y",
    "outputId": "44a533e4-4df0-494d-b82f-6bd44e5240c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF topics based on tfidf matrix:\n",
      "Topic #0: clean wa hotel floor facility bathtub room renovation hip tidy\n",
      "Topic #1: bed comfortable wa comfy terrible lovely super minimalist spacious mattress\n",
      "Topic #2: room small wa extremely extra cold spacious bathroom especially inviting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf.fit_transform(tfidf_sparse)\n",
    "print('NMF topics based on tfidf matrix:')\n",
    "print_top_terms(nmf, tfidf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647619765373,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "vLZwpwgMyH7Y",
    "outputId": "e5eaeedf-8f2c-4227-82c1-b9def4c602af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          n_components=3, random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Latent Dirichlet allocation (LDA)\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=3, random_state=1, learning_method='online', learning_offset=50.)\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1647619765591,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "6w4jvQFgyH7Z",
    "outputId": "ff229dfc-595f-44f6-fcde-c348a014cf2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA topics based on term-document matrix:\n",
      "Topic #0: window clean ha towel just air 5 loud lift bed\n",
      "Topic #1: wa room bed shower small comfortable clean cold noisy great\n",
      "Topic #2: room didnt bathroom hotel door way sound use work mattress\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda.fit_transform(tf_sparse)\n",
    "print('LDA topics based on term-document matrix:')\n",
    "print_top_terms(lda, tf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1647619765784,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "4URuWwN0yH7Z",
    "outputId": "c066274c-82da-48bd-95a1-c7fb47e4c743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA topics based on tfidf matrix:\n",
      "Topic #0: clean wa comfortable bed room elevator window air towel shower\n",
      "Topic #1: wa room great cold facility quiet bed spacious shower noisy\n",
      "Topic #2: room small bathroom wa extra sound dirty poor extremely didnt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda.fit_transform(tfidf_sparse)\n",
    "print('LDA topics based on tfidf matrix:')\n",
    "print_top_terms(lda, tfidf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12132,
     "status": "ok",
     "timestamp": 1647619777914,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "g3WUjmFWyH7Z",
    "outputId": "c0277275-e930-481c-bf03-1ca4da7bff80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing time: 10.317 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Grid search for the best number of topics (and other parameters) for LDA\n",
    "t0 = time()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_components': [2,3,4,5,6,7,8,9,10]}\n",
    "lda = LatentDirichletAllocation(random_state=1, learning_method='online', learning_offset=50.)\n",
    "lda_grid = GridSearchCV(lda, param_grid)\n",
    "lda_grid.fit(tf_sparse)\n",
    "print(\"Computing time: %0.3f seconds.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1647619778064,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "8A3PvIMByH7a",
    "outputId": "7470e097-a890-4628-be98-3d6e93c3582d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model's params:  {'n_components': 2}\n",
      "Best log likelihood score:  -1702.5776377326442\n",
      "Model perplexity:  469.31129973020967\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model's params: \", lda_grid.best_params_)\n",
    "print(\"Best log likelihood score: \", lda_grid.best_score_)\n",
    "print(\"Model perplexity: \", lda_grid.best_estimator_.perplexity(tf_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647619778064,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "DpHiEAtzyH7a",
    "outputId": "31a53c21-8fd0-4bb6-df6b-54b048eac5d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          n_components=2, random_state=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(\n",
    "    n_components=2, random_state=1, learning_method='online', learning_offset=50.)\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1647619778481,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "QJLNBPp0yH7a",
    "outputId": "4d5bb641-c458-43f8-c013-5e935b7759e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA topics based on term-document matrix:\n",
      "Topic #0: bathroom hotel door didnt use window mattress glass clean work\n",
      "Topic #1: wa room bed shower small clean comfortable noisy bathroom cold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda.fit_transform(tf_sparse)\n",
    "print('LDA topics based on term-document matrix:')\n",
    "print_top_terms(lda, tf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1647619778938,
     "user": {
      "displayName": "Xavier Babu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00625526060932236782"
     },
     "user_tz": 240
    },
    "id": "CilrwIlgyH7a",
    "outputId": "445a6ddd-f8c8-47a7-de7e-3c3ef69d16bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA topics based on tfidf matrix:\n",
      "Topic #0: comfortable bed wa clean hotel bathroom door elevator didnt window\n",
      "Topic #1: room wa small clean bed shower noisy great cold facility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda.fit_transform(tfidf_sparse)\n",
    "print('LDA topics based on tfidf matrix:')\n",
    "print_top_terms(lda, tfidf_dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "topic_modeling_hotel207reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
